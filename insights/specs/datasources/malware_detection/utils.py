import os
import logging
import time
from datetime import datetime

from insights.client.constants import InsightsConstants as constants
from insights.specs.datasources.malware_detection.config import (
    LAST_FILESYSTEM_SCAN_FILE,
    LAST_PROCESSES_SCAN_FILE,
)

logger = logging.getLogger(__name__)


#
# Utility functions
# Mainly for including / excluding certain directories for scanning
# And also for finding files that have been modified recently
#
def get_toplevel_dirs():
    """
    Returns a list of the top level directories directly under root (/),
    """
    toplevel_dirs = sorted(
        filter(lambda x: not os.path.islink(x), map(lambda x: "/" + x, os.listdir("/")))
    )
    return toplevel_dirs


def is_same_file_or_root(file1, file2):
    # Catch possible permission denied error with fuse mounted filesystems. Yes, even for root!
    try:
        if os.path.samefile(file1, file2) or os.path.samefile(file1, "/"):
            return True
    except Exception as err:
        logger.debug(
            "Encountered exception running os.path.samefile('%s', '%s'): %s.  Trying string comparison ...",
            file1,
            file2,
            str(err),
        )
        if file1 == file2 or file1 == "/":
            return True
    return False


def get_parent_dirs(item, parent_dir_list, base_case="/"):
    """
    Get a list of parent directories of a particular filesystem item, stopping at base_case (root by default)
    Eg for get_parent_dirs('/path/to/some/item', parent_dir_list) ->
        parent_dir_list = ['/path', '/path/to', '/path/to/some', '/path/to/some/item']
    """
    if is_same_file_or_root(item, base_case):
        return
    get_parent_dirs(os.path.dirname(item), parent_dir_list, base_case)
    parent_dir_list.append(item)


def process_include_items(include_items=[]):
    """
    Process the include items to a get list of directories to be scanned
    If there are no entries then get the list of top level directories under root (/),
    :return: a list of directories to be scanned.  It never returns an empty list.
    """
    default_values = get_toplevel_dirs()

    logger.debug("Parsing include items ...")
    parsed_list = []
    for item in include_items:
        item = item.strip()
        if not item or item.startswith("#"):
            continue
        include_item = os.path.normpath(item).replace("//", "/")
        if os.path.exists(include_item):
            # ignore the include_item if its not a full directory path
            if not include_item.startswith("/"):
                logger.debug("Skipping partial directory path '%s' ...", include_item)
                continue
            elif os.path.islink(include_item):
                logger.debug("Skipping link '%s' ...", include_item)
                continue
            elif include_item == "/":
                # Found / in include item list.  No need to get the other items because / trumps all
                logger.debug(
                    "Found root directory in list of items to scan.  Ignoring the other items ..."
                )
                parsed_list = default_values
                break
            else:
                parsed_list.append(include_item)
        else:
            logger.debug("Skipping missing item '%s' ...", include_item)

    if not parsed_list:
        logger.debug(
            "No items specified to be scanned.  Using default values %s ...",
            default_values,
        )
        parsed_list = default_values
    else:
        # Remove any duplicates and any children of parent directories before returning
        parsed_list = remove_child_items(sorted(list(set(parsed_list))))

    logger.debug("Include items: %s", parsed_list)
    return parsed_list


def process_exclude_items(exclude_items=[]):
    """
    Process the exclude items to get list of directories to NOT be scanned
    :return: a list of directories to not be scanned if any, otherwise an empty list
    """
    logger.debug("Parsing exclude items ...")
    parsed_list = []
    for item in exclude_items:
        item = item.strip()
        if not item or item.startswith("#"):
            continue
        exclude_item = os.path.normpath(item).replace("//", "/")
        if os.path.exists(exclude_item):
            # ignore the exclude_item if its not a full directory path
            if exclude_item == "/":
                # Found / in exclude list.  No need to get the other items because / trumps all
                logger.debug(
                    "Found root directory in the exclude list.  Expanding it to all toplevel directories ..."
                )
                parsed_list = get_toplevel_dirs()
                break
            elif not exclude_item.startswith("/"):
                logger.debug("Skipping partial directory path '%s' ...", exclude_item)
                continue
            else:
                parsed_list.append(exclude_item)
        else:
            logger.debug("Skipping missing item '%s' ...", exclude_item)

    if not parsed_list:
        logger.debug("No items specified to be excluded")
    else:
        # Remove any duplicates and any children of parent directories before returning
        parsed_list = remove_child_items(sorted(list(set(parsed_list))))

    logger.debug("Exclude items: %s", parsed_list)
    return parsed_list


def remove_child_items(item_list):
    """
    For a list of filesystem items, remove those items that are duplicates or children of other items
    Eg, for remove_child_items['/path/to/some/item/child', '/path/to/another/item', '/path/to/some/item']
        returns ['/path/to/another/item', '/path/to/some/item']
    If one if the items is root, then it wins
    Also, all items should be the full path starting at root (/).  Any that aren't are removed
    """
    if "/" in item_list:
        return ["/"]

    # Remove duplicates and any non-full path items
    item_list = sorted(list(set(filter(lambda x: x.startswith("/"), item_list))))
    remove_items = set([])
    for i, item1 in enumerate(item_list[:-1]):
        for item2 in item_list[i + 1 :]:
            if item1 != item2 and item2.startswith(item1 + "/"):
                remove_items.add(item2)
    for remove_item in remove_items:
        item_list.remove(remove_item)
    return sorted(list(set(item_list)))


def remove_included_excluded_items(included_items, excluded_items):
    """
    Go through the list of included items and remove any that are in the exclude list,
        or are children of excluded items (no need to scan an included item if its parent is to be excluded)
    """
    # Clean up the lists, just in case this hasn't been done already
    included_items = remove_child_items(included_items)
    excluded_items = remove_child_items(excluded_items)

    remove_items = set([])
    for included_item in included_items:
        for excluded_item in excluded_items:
            if excluded_item == included_item or included_item.startswith(
                excluded_item + "/"
            ):
                remove_items.add(included_item)
    for remove_item in remove_items:
        included_items.remove(remove_item)
    return included_items


def process_include_exclude_items(
    include_items=[], exclude_items=[], exclude_mountpoints=[]
):
    """
    Process the include and exclude items, where the exclude items are effectively subtracted from the include_items.
    It builds a scan_dict dictionary of items to scan keyed by the filesystem top level directories.
    Only the toplevel directories from items in the include_items list will be present in scan_dict.
    scan_dict = {'/boot': {'include': ['/boot/include/me', ...], 'exclude: ['/boot/exclude/me', ...]},
                 '/etc': {'include': ['/etc/include/me', ...], 'exclude: ['/etc/exclude/me', ...]},
                 ...
    :return: scan_dict
    """
    # Get a list of excluded items from the exclude file and network filesystem mountpoints
    initial_exclude_list = process_exclude_items(exclude_items)
    final_exclude_list = remove_child_items(
        list(set(exclude_mountpoints) | set(initial_exclude_list))
    )
    logger.debug("Final exclude items: %s", final_exclude_list)

    # Get a list of included items from the include file, minus the excluded items
    initial_include_list = process_include_items(include_items)
    if not initial_include_list:
        logger.error(
            "No filesystem items to scan because the include items doesn't contain any valid items"
        )
        return {}
    final_include_list = remove_included_excluded_items(
        initial_include_list, final_exclude_list
    )
    logger.debug(
        "Final include items after removing exclude items: %s", final_include_list
    )
    if not final_include_list:
        logger.error(
            "No filesystem items to scan because the specified exclude items cancel them out"
        )
        return {}

    # This is the dictionary that will hold all the items to scan (after processing the include and exclude items)
    # It will be keyed by each of the toplevel directories containing items to scan
    # yara will scan each of the toplevel dir's 'include' keys (if present), or just the toplevel dir itself
    scan_dict = {}

    # Populate the scan_dict by creating keys for each toplevel directory of the items to include/scan
    # Create an 'include' key for each toplevel directory containing items to include in that toplevel directory
    logger.debug("Populating scan_dict's include items ...")
    for include_item in final_include_list:
        item_subpaths = []
        get_parent_dirs(include_item, item_subpaths)
        include_item_toplevel_dir = item_subpaths[0]
        if include_item_toplevel_dir not in scan_dict:
            # Create an 'include' key if the item to scan isn't just the toplevel directory itself
            scan_dict[include_item_toplevel_dir] = (
                {"include": set([include_item])}
                if include_item != include_item_toplevel_dir
                else {}
            )
        else:
            scan_dict[include_item_toplevel_dir]["include"].add(include_item)

    logger.debug("Scan dict after adding include items: %s", scan_dict)

    # Populate an 'exclude' key for the toplevel dirs in the scan_dict that also have items to exclude
    # Or remove the toplevel dirs from the scan dict where the toplevel dir itself is to be excluded
    logger.debug("Populating scan_dict's exclude items ...")
    for exclude_item in final_exclude_list:
        item_subpaths = []
        get_parent_dirs(exclude_item, item_subpaths)
        exclude_item_toplevel_dir = item_subpaths[0]
        if exclude_item_toplevel_dir not in scan_dict:
            # This exclude_item's toplevel dir isn't in the scan dict, so skip it (since its not being included)
            continue
        if "exclude" not in scan_dict[exclude_item_toplevel_dir]:
            # Create the 'exclude' key if it doesn't already exist
            scan_dict[exclude_item_toplevel_dir]["exclude"] = {
                "items": [],
                "subpaths": set([]),
            }

        scan_dict[exclude_item_toplevel_dir]["exclude"]["items"].append(exclude_item)

        # Add the list of subpaths leading to this exclude item.
        # The subpaths are needed later for listing the contents each subpath
        scan_dict[exclude_item_toplevel_dir]["exclude"]["subpaths"].update(
            item_subpaths
        )

    logger.debug("Scan dict after adding exclude items: %s", scan_dict)

    # For each toplevel dir with items to exclude, re-populate the include key with directory content listings
    # of the subpaths, minus the items to exclude and only including items to include.  Yep, its complicated.
    # These directory listings will be used with yara's --scan-list option
    logger.debug(
        "Re-populating scan_dict's include items with directory content listings to pass to yara ..."
    )
    for toplevel_dir in scan_dict:
        if "exclude" not in scan_dict[toplevel_dir]:
            continue

        # Get directory listings of each of the subpaths
        if "include" in scan_dict[toplevel_dir]:
            scan_items = set(scan_dict[toplevel_dir]["include"])
        else:
            scan_items = set([])
        toplevel_dir_exclude = scan_dict[toplevel_dir]["exclude"]
        for exclude_item in toplevel_dir_exclude["items"]:
            subpaths = []
            get_parent_dirs(exclude_item, subpaths)
            for i, subpath in enumerate(subpaths[:-1]):
                dir_list = os.listdir(subpath)
                dir_list = sorted(map(lambda x: subpath + "/" + x, dir_list))
                dir_list.remove(subpaths[i + 1])
                scan_items.update(dir_list)

        # Go through the list of scan items and remove any exclude items or exclude item subpaths
        for scan_item in list(scan_items):
            for exclude_item in toplevel_dir_exclude["items"]:
                if scan_item == exclude_item or scan_item.startswith(
                    exclude_item + "/"
                ):
                    scan_items.remove(scan_item)
                    break
            else:
                for exclude_subpath in toplevel_dir_exclude["subpaths"]:
                    if scan_item == exclude_subpath:
                        scan_items.remove(scan_item)

        # If there is an include list, make sure the scan_items only include items in the include list
        if "include" in scan_dict[toplevel_dir]:
            for maybe_include in list(scan_items):
                if os.path.islink(maybe_include) or (
                    not os.path.isfile(maybe_include)
                    and not os.path.isdir(maybe_include)
                ):
                    scan_items.remove(maybe_include)
                    continue
                if any(
                    [
                        maybe_include == definitely_include
                        or maybe_include.startswith(definitely_include + "/")
                        for definitely_include in scan_dict[toplevel_dir]["include"]
                    ]
                ):
                    continue
                else:
                    scan_items.remove(maybe_include)

        # Overwrite the existing include key list with the new list of scan_items
        scan_dict[toplevel_dir]["include"] = sorted(list(scan_items))

    logger.debug("Final scan_dict: %s", scan_dict)
    return scan_dict


def get_scan_since_timestamp(scan_since_option, since):
    """
    Return a unix timestamp corresponding to how long ago to scan for files or processes (depending on scan_since_option)
    Valid values of 'since' are integers > 0 meaning the number of days back in time from now,
                             or 'last' meaning get the timestamp of the last scan
    If 'since' is not one of these valid values, then terminate
    """
    now = time.time()
    timestamp_file = (
        LAST_FILESYSTEM_SCAN_FILE
        if scan_since_option == "filesystem_scan_since"
        else LAST_PROCESSES_SCAN_FILE
    )

    def get_lastscan_timestamp(scan_since_option, lastscan):
        try:
            # Convert the datetime string into a unix timestamp
            lastscan_seconds = float(
                datetime.strptime(lastscan, "%Y-%m-%dT%H:%M:%S.%f").strftime("%s")
            )
            if lastscan_seconds > now:
                raise RuntimeError("Last scan time is in the future.")
        except Exception as err:
            logger.error(
                "Error getting time of last malware scan: %s.  Ignoring '%s: last' option ...",
                str(err),
                scan_since_option,
            )
            return None
        return lastscan_seconds

    if isinstance(since, str) and since.lower().startswith("l"):
        # Get the timestamp of the last scan
        if os.path.isfile(timestamp_file):
            with open(timestamp_file) as f:
                lastscan = f.readline().strip()
            return get_lastscan_timestamp(scan_since_option, lastscan)
        else:
            logger.info(
                "File %s doesn't exist for '%s: last' option.  Continuing ...",
                timestamp_file,
                scan_since_option,
            )
            return None
    elif isinstance(since, str):
        logger.error(
            "Unknown value '%s' for %s option.  Valid values are integers >= 1 and 'last'",
            since,
            scan_since_option,
        )
        exit(constants.sig_kill_bad)

    try:
        since_int = int(since)
        if since_int >= 1:
            return now - (since_int * 86400)  # 86400 seconds in a day
        else:
            raise ValueError(
                "Invalid %s value %s.  Valid values are integers >= 1 and 'last'"
                % (scan_since_option, since)
            )
    except ValueError as e:
        logger.error(str(e))
        exit(constants.sig_kill_bad)


def is_recent_mtime(item, timestamp):
    """
    Return True if the given 'item' has a modification time that is newer than 'timestamp'
    Return False otherwise, or if the the 'item' is a link or another non-file type (eg pipes)
    """
    if os.path.exists(item) and not os.path.islink(item) and os.path.isfile(item):
        return os.path.getmtime(item) > timestamp
    return False


def find_modified_in_directory(directory, timestamp, output_file):
    """
    Find files in 'directory' that have been created/modified since 'timestamp'
    and write their names to 'output_file'
    """
    for root, dirs, files in os.walk(directory):
        for afile in files:
            path = os.path.join(root, afile)
            if is_recent_mtime(path, timestamp):
                output_file.write(path + "\n")


def find_modified_include_items(item_list, timestamp, output_file):
    """
    Find files in the given list of items (files/directories) that have been created/modified since 'timestamp'
    and write their names to 'output_file'
    """
    for item in item_list:
        if os.path.isdir(item):
            find_modified_in_directory(item, timestamp, output_file)
        else:
            if is_recent_mtime(item, timestamp):
                output_file.write(item + "\n")
